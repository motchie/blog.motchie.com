---
title: "アクセシビリティ=マルチモダリティ・アーキテクチャ"
date: 2017-05-18T00:00:05+09:00
draft: false
description: "システムの入出力が複数のモダリティで提供されている「マルチモダリティ」を提唱し、これがアクセシブルなシステムの条件であることを説明しています。"
---

<section>
    <h3>はじめに</h3>
    <p>この記事は<a href="http://accfes.com/seminar_page07.html">アクセシビリティの祭典2017『話題の技術とアクセシビリティ（IoT、VR、AR、音声など）』</a>のトークセッションでお話しようと準備した内容をまとめたものです。</p>
    <p>ここまで、<a href="/ja/accessibility/thinking-about-accssibility-of-iot-systems/" lang="en">IoT</a>や<a href="/ja/accessibility/organize-issues-of-accessibility-of-virtual-reality/">VRシステム</a>や
        <a href="/ja/accessibility/organize-issues-of-accessibility-of-virtual-assistant/">AI音声アシスタント</a>の事例を通して、それらのシステムのアクセシビリティについて見てきました。</p>
    <p>では、これらの事例から、私たちが今後アクセシブルなシステムを設計する上で大切な共通の知見を得ることはできるでしょうか。</p>
    <div><img class="entry-image" alt="[イメージ写真]" src="/images/multimodality-architecture.jpeg" />
        <p class="entry-image-credit" lang="en">Photo credit: <a href="https://www.flickr.com/photos/michaelgallagher/13986993793/">michaelseangallagher</a> via <a href="https://visualhunt.com/re/2a31c9">Visualhunt</a> / <a href="http://creativecommons.org/licenses/by-sa/2.0/"> CC BY-SA</a>
        </p>
    </div>
</section>

<!--more-->

<section>
    <h3>音声アシスタントからヒントを得る</h3>
    <p>私は、ヒントは音声アシスタントにあると考えました。</p>
    <p>例えばSiriやCortana、Googleアシスタントは、音声アシスタントの機能もありますが、音声の代わりにテキストでも指示を出し、結果をテキストで受けとることができます。</p>
    <p>つまり、発話による指示(入力)と聴覚に対する音声でのフィードバック(出力)に限らず、(支援技術によるものも含め)テキストによる指示(入力)とテキストでのフィードバック(出力)が可能になっています。</p>
    <p>このように、システムに対して複数の感覚器による同等の入出力が可能であるシステムを <dfn>「マルチモダリティ・アーキテクチャ(multimodality architecture)」</dfn>と呼ぶことにします。</p>
    <p>この概念で新規システムを設計すると、シングルモダリティなシステムに比べアクセシビリティが向上すると考えられます。また、同じ概念を用いて既存システムのアクセシビリティを評価することができるのではないかと考えます。</p>
</section>
<section>
    <h3>モダリティという用語</h3>
    <p>「モダリティ」という用語は、さまざまなジャンルでさまざまな定義がありますが、ここでは、人間とコンピューターのインタラクションの分野で用いられる以下の定義を指しています。</p>
    <blockquote cite="https://en.m.wikipedia.org/wiki/Modality">
        In the context of human–computer interaction, a modality is the classification of a single independent channel of sensory input/output between a computer and a human.
    </blockquote>
    <p>つまりは、人間同士、あるいは人間とコンピューター間の情報伝達における手段を指し、そのようなコミュニケーションにおけるチャネルや経路ということができます。</p>
    <p>人間とコンピューター間のモダリティの例:</p>
    <ul>
        <li>視覚</li>
        <li>聴覚</li>
        <li>振動その他の動き</li>
    </ul>
</section>
<section>
    <h3>マルチモダリティ・アーキテクチャ</h3>
    <p>クラウド・コンピューティングと、スマートフォン、タブレットの急速な普及に伴って、クラウドを利用したサービスを展開する際には「マルチデバイス対応」を行うことが一般的になりました。サービス・デザインや設計・開発のすべてにおいて、この「マルチデバイス対応」を意識しておく必要があります。</p>
    <p>同様に、今後何かサービスを開発する場合には、「マルチモダリティ・アーキテクチャ」を採用する方がよりアクセシブルなサービスになると考えます。</p>
</section>
<section>
    <h3>「マシンリーダブル=アクセシビリティ」との関連</h3>
    <p>昨年の「アクセシビリティの祭典」のスローガンでもあり、今年もセッションが設けられる「マシンリーダブル=アクセシビリティ」については、「リーダブル」と書いてありますので、 主に消費するコンテンツのアクセシビリティに主眼が置かれていると考えます。
    </p>
    <p>これに対し、IoTや音声アシスタントなど、入出力を伴うシステム(サービスやアプリケーション)においては、出力である<span lang="en">&quot;read&quot;</span>以外に、 ユーザーからシステムに対する入力に関してもカバーする必要があります。</p>
    <p>このようにカバーする範囲を広げてアクセシビリティを考える場合には、「マルチモダリティ」が重要であると考えます。
    </p>
</section>
<section>
    <h3>マルチモダリティの視点で、既存システムのアクセシビリティを評価し改善方針を立てる</h3>
    <p>ここまで議論してきた、IoT、VRシステム、AI音声アシスタントのアクセシビリティのすべてが、この「マルチモダリティ」で評価し、改善方針を立てることができます。</p>
    <dl>
        <dt>電源の状態をLEDランプだけで知らせるIoTデバイス</dt>
        <dd>視覚に頼った情報提供のため、モダリティが複数ではありません。ブザーを鳴らす、バイブレーションで振動することで、マルチモダリティになります。</dd>
        <dt>ヘッドトラッキング機能付きHMDを使うVRシステム</dt>
        <dd>視覚とに頼った情報提供である可能性があります。3次元サウンドを併用することで、マルチモダリティになります。</dd>
        <dt>音声のみで指示を出し、音声でフィードバックを返すスマートスピーカー</dt>
        <dd>聴覚に頼った入力および出力のため、モダリティが複数ではありません。スマートフォン・アプリなど、別の入出力チャネルを設けることで、マルチモダリティになります。</dd>
    </dl>
</section>
<section>
    <h3>コンテンツのアクセシビリティへの応用</h3>
    <p>「マルチモダリティ・アーキテクチャ」は、システムの入出力に注目した概念だと書きましたが、より拡張した概念ですので、もちろんコンテンツにも応用できます。</p>
    <p>例えば、代替テキストのない画像については、視覚に頼った情報提供であり、モダリティが複数ではないと考えることができます。これは、代替テキストを提供することで、マルチモダリティになると考えることができます。</p>
</section>
<section>
    <h3>まとめ</h3>
    <p>コンテンツだけでなく、アプリケーションやシステムを設計する際には、そのユーザーである人間とのモダリティが複数あるかどうかに注目します。</p>
    <p>その結果、複数のモダリティを提供する設計になっていれば、単一のモダリティに比べ、アクセシビリティが向上していると言えます。</p>
</section>
